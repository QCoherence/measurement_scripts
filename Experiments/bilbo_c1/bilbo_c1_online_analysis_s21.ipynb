{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6cebae6-7c74-46a9-b8f5-01ae80070903",
   "metadata": {},
   "source": [
    "<h1>Analysis of Bilbo C1 chip</h1>\n",
    "Online analysis script used to pre-analyse the data collected during the cooldown of the chip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6504013c-2f8a-4667-bb9b-eeb1f56adbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_name = 'bilbo_c1'                    # name of the chip in the fridge\n",
    "db_name = '20220923_sc-ncr_chip_characterisation.db'   # name of the database\n",
    "user = 'sc-ncr'                               # who is performing measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed766a25-e71a-4d1b-b855-17db80a2b7f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Basic imports</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "267a50c9-2bc5-4de4-b0ff-74e1659bfa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from resonator_tools import circuit\n",
    "\n",
    "import qcodes as qc\n",
    "from qcodes import initialise_database, load_by_run_spec\n",
    "from qcodes.dataset.plotting import plot_by_id\n",
    "\n",
    "import scipy.optimize\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "db_path  = os.path.join(r'D:\\QMET' + '\\\\' + sample_name + '\\\\', db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee53a4e-8668-4e92-892c-aaaa1be32bff",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Utils</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a37197a7-537c-4718-ba6e-64ecba5f17a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_peaks(base_array, threshold):\n",
    "    '''Detect the argmax of peaks whose value is above threshold'''\n",
    "    \n",
    "    # study =base_array-np.min(np.abs(base_array)) #if we want relative threshold\n",
    "    study = base_array #absolute threshold\n",
    "    peaks=[]\n",
    "    idx=0\n",
    "    L = len(study)\n",
    "    while idx < L:\n",
    "        ph = study[idx]\n",
    "        if ph > threshold:\n",
    "            if idx < L-1:\n",
    "                i2 = idx+1\n",
    "                ph2= ph+1\n",
    "                while  i2 < L and ph2 >= ph:\n",
    "                    ph2 = study[i2]\n",
    "                    i2 +=1\n",
    "                    \n",
    "                peaks.append(idx + np.argmax(study[idx:i2])) \n",
    "                idx=i2\n",
    "            else: \n",
    "                peaks.append(idx)\n",
    "        idx+=1\n",
    "    \n",
    "    return peaks\n",
    "\n",
    "def remove_overdetection_peaks(base_array, freq_array, peaks, minimum_freq_spacing):\n",
    "    '''Remove the peaks indexes that are within minimum_freq_spacing of each other'''\n",
    "    \n",
    "    spacing = 0 \n",
    "    grouped_peaks = [[peaks[0]]]\n",
    "    for i in range(1, len(peaks)):\n",
    "        pk = peaks[i]\n",
    "        spacing = np.abs(freq_array[pk] - freq_array[peaks[i-1]])\n",
    "\n",
    "        if spacing <= minimum_freq_spacing :\n",
    "            grouped_peaks[-1].append(pk)\n",
    "        else :\n",
    "            grouped_peaks.append([pk])\n",
    "            \n",
    "    new_peaks = []\n",
    "    for group in grouped_peaks:\n",
    "        if len(group) > 1:\n",
    "            n_peaks = group[0] + np.argmax(base_array[group[0]:group[-1]])\n",
    "        else :\n",
    "            n_peaks = group[0]\n",
    "        new_peaks.append(n_peaks)\n",
    "    \n",
    "    return new_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8b0060-9f4e-447d-9e68-af5b52f82a92",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Data loading</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bb91c96-dae4-42a1-9bfc-8662d6e1e844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vna_1dtrce_p0dbm_cnt5ghz_spn3ghz #1@D:\\QMET\\bilbo_c1\\20220923_sc-ncr_chip_characterisation.db\n",
      "---------------------------------------------------------------------------------------------\n",
      "ZNB20_S21_S21_frequency - numeric\n",
      "ZNB20_S21_magnitude - numeric\n",
      "ZNB20_S21_phase - numeric\n"
     ]
    }
   ],
   "source": [
    "RUN_ID = 1\n",
    "qc.initialise_or_create_database_at(db_path)\n",
    "dataset = qc.load_by_run_spec( captured_run_id=RUN_ID)\n",
    "print(dataset)\n",
    "\n",
    "#plt.plot(f, phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d419310-177d-44a6-8350-ea905853ab45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s21_vs_dcI_3.7Ghz_to_5.5GHz_0.1nA #51@D:\\QMET\\bilbo_c1\\20221118_sc-ncr_s21_meas.db\n",
       "----------------------------------------------------------------------------------\n",
       "current_source_current - numeric\n",
       "adwin_output_in_current - numeric\n",
       "ZNB20_S21_S21_frequency - numeric\n",
       "ZNB20_S21_magnitude - numeric\n",
       "ZNB20_S21_phase - numeric"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_name = '20221118_sc-ncr_s21_meas.db'\n",
    "db_path  = os.path.join(r'D:\\QMET' + '\\\\' + sample_name + '\\\\', db_name)\n",
    "\n",
    "RUN_ID = 51\n",
    "qc.initialise_or_create_database_at(db_path)\n",
    "dataset = qc.load_by_run_spec( captured_run_id=RUN_ID)\n",
    "dataset\n",
    "#plt.plot(f, phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07754d5e-5433-413c-8d99-d921c2e8ef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = dataset.get_parameter_data('ZNB20_S21_S21_frequency')['ZNB20_S21_S21_frequency']['ZNB20_S21_S21_frequency']\n",
    "mag = dataset.get_parameter_data('ZNB20_S21_magnitude')['ZNB20_S21_magnitude']['ZNB20_S21_magnitude']\n",
    "phi = dataset.get_parameter_data('ZNB20_S21_phase')['ZNB20_S21_phase']['ZNB20_S21_phase']\n",
    "# pwr = dataset.get_parameter_data('mw_source_power')['mw_source_power']['mw_source_power']\n",
    "# mw_f = dataset.get_parameter_data('mw_source_frequency')['mw_source_frequency']['mw_source_frequency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace5ad3-db02-48f5-b795-9d67653bdd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f[:mag.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5304182b-7b49-473e-9d3d-0d3841c7f360",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_mag = mag/np.max(np.abs(mag))\n",
    "# normalized_phase = np.empty(mag.shape)\n",
    "# for i in range(mag.shape[0]):\n",
    "#     # Normalize for each power value\n",
    "#     x = mag[i, :]\n",
    "#     y = phi\n",
    "#     normalized_mag[i,  :] = x/np.max(np.abs(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a11500-8888-4e7f-9492-e4b6ecc48a63",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Data analysis and plotting S21-Dispersion fit</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb815d84-3142-4309-9a1b-c5f5b8f7f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_peaks = []\n",
    "phase_peaks= []\n",
    "m_peaks = check_for_peaks(10*np.log(mag), threshold=-80)\n",
    "m_peaks = remove_overdetection_peaks(10*np.log(mag), f, m_peaks, minimum_freq_spacing=0.03e9)\n",
    "mag_peaks.append(m_peaks)\n",
    "    \n",
    "    # phi_peaks = check_for_peaks(phi[i, :, 0], threshold = 0)\n",
    "    # phi_peaks = remove_overdetection_peaks(phi[i, :, 0], mw_f[i, :, 0], phi_peaks, minimum_freq_spacing=0.3e9)\n",
    "    # phase_peaks.append(phi_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5f84e4-c8ce-4dd0-80ec-0f4966891e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.plot(f,  10*np.log(mag))\n",
    "plt.vlines(f[tuple(mag_peaks)], np.min(10*np.log(mag)), np.max(10*np.log(mag)),color='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb2dcef-e390-43fb-8d30-4fda35a28ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f[tuple(mag_peaks)], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbd127a-ea86-49dd-a558-da4ed5d60906",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "offset_K = 7*4-2\n",
    "\n",
    "k_idx = np.arange(offset_K, offset_K + len(mag_peaks[0]), 1)\n",
    "found_peaks = f[tuple(mag_peaks)]\n",
    "k_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca558c9-c218-43f7-b7f6-2cf4da9db965",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_idx, found_peaks, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9260585e-ccd9-4f8e-996b-03115e573232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispersion_fun(x, omega_p, cap_ratio, cste):\n",
    "    ka = x*np.pi/2500 + cste # 2500 junctions\n",
    "    \n",
    "    val = omega_p*np.sqrt((1-np.cos(ka))/(1-np.cos(ka)+0.5*cap_ratio))\n",
    "    return val\n",
    "\n",
    "fit = scipy.optimize.curve_fit(dispersion_fun, k_idx, found_peaks/found_peaks[-1], bounds=(0, np.inf),  maxfev=10000 )\n",
    "# print(fit[0])\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(k_idx, found_peaks, '.')\n",
    "ks = np.linspace(0,k_idx[-1], num=250)\n",
    "plt.plot(ks, [dispersion_fun(k, *fit[0])*found_peaks[-1] for k in ks] ,'--')\n",
    "print(\"Plasma frequency: %.2e Hz, Cg/Cj: %.2e\" % (fit[0][0]*found_peaks[-1], fit[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71e69de-b102-4b83-875e-a7d0f6e59310",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<h2>Data analysis and plotting - S21 vs B field</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b73d6b8-5fd2-4837-8d22-d793f5409fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = '20221118_sc-ncr_s21_meas.db'\n",
    "db_path  = os.path.join(r'D:\\QMET' + '\\\\' + sample_name + '\\\\', db_name)\n",
    "\n",
    "qc.initialise_or_create_database_at(db_path)\n",
    "\n",
    "RUN_ID = 56\n",
    "\n",
    "\n",
    "dataset = qc.load_by_run_spec(captured_run_id=RUN_ID)\n",
    "vnadc_vna_dict = dataset.to_pandas_dataframe_dict()\n",
    "#plt.plot(f, phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644fd9c2-2cae-4d43-9c23-ab7ebf7216cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# VNA spectra\n",
    "vnadc_vna_0 = vnadc_vna_dict['ZNB20_S21_magnitude']\n",
    "vnadc_vna_1 = vnadc_vna_0.reset_index()\n",
    "\n",
    "frq = vnadc_vna_1['ZNB20_S21_S21_frequency'].to_numpy()\n",
    "mag = vnadc_vna_1['ZNB20_S21_magnitude'].to_numpy()\n",
    "Ib = vnadc_vna_1['current_source_current'].to_numpy()\n",
    "\n",
    "freq_size =  np.unique(frq).size\n",
    "current_size = np.unique(Ib).size\n",
    "\n",
    "\n",
    "m_size = (current_size, freq_size)\n",
    "frq = np.reshape(frq, m_size)\n",
    "mag = np.reshape(mag, m_size)\n",
    "Ib = np.reshape(Ib, m_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd402c8b-fcb9-4f55-8919-7b1dee5e89bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ib.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a314a34-0d6f-4a00-970a-dd07a793caa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_phase = np.empty(mag.shape)\n",
    "# for i in range(mag.shape[0]):\n",
    "#     # Normalize for each power value\n",
    "#     x = mag[i, :]\n",
    "#     y = phi\n",
    "#     normalized_mag[i,  :] = x/np.max(np.abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e474ad-91ac-41a7-abc2-b4b57a1a18ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mag_peaks = []\n",
    "phase_peaks= []\n",
    "m_peaks = check_for_peaks(10*np.log(mag[0,:]), threshold=-70)\n",
    "m_peaks = remove_overdetection_peaks(10*np.log(mag[0,:]), frq[0,:], m_peaks, minimum_freq_spacing=0.04e9)\n",
    "mag_peaks.append(m_peaks)\n",
    "    \n",
    "    # phi_peaks = check_for_peaks(phi[i, :, 0], threshold = 0)\n",
    "    # phi_peaks = remove_overdetection_peaks(phi[i, :, 0], mw_f[i, :, 0], phi_peaks, minimum_freq_spacing=0.3e9)\n",
    "    # phase_peaks.append(phi_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30319e37-5428-454c-8538-aecb53a8fe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.plot(frq[0,:],  10*np.log(mag[0,:]))\n",
    "plt.vlines(frq[0,tuple(mag_peaks)], np.min(10*np.log(mag[0,:])), np.max(10*np.log(mag[0,:])),color='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03278eb-62df-4d04-9d7d-ba60da07fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_peaks = []\n",
    "phase_peaks= []\n",
    "for i in range(mag.shape[0]):\n",
    "    m_peaks = check_for_peaks(10*np.log(mag[i,:]), threshold=-72)\n",
    "    m_peaks = remove_overdetection_peaks(10*np.log(mag[i,:]), frq[i, :], m_peaks, minimum_freq_spacing=0.03e9)\n",
    "    mag_peaks.append(m_peaks)\n",
    "    \n",
    "    # phi_peaks = check_for_peaks(phi[i, :, 0], threshold = 2.7)\n",
    "    # phi_peaks = remove_overdetection_peaks(phi[i, :], frq[i, :], phi_peaks, minimum_freq_spacing=0.5e9)\n",
    "    # phase_peaks.append(phi_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584b06a5-f760-4277-a6e8-d9d63082adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))\n",
    "ax1 = fig.add_subplot(111)\n",
    "# ax2 = fig.add_subplot(122)\n",
    "\n",
    "\n",
    "for i in range(mag.shape[0]):\n",
    "    peaks =  mag_peaks[i]\n",
    "    ax1.scatter(frq[i, peaks],[Ib[i, 0]]*len(peaks), color='r', s=0.5)\n",
    "    \n",
    "    # peaks =  phase_peaks[i]\n",
    "    # ax2.scatter(frq[i, peaks, 0],[Ib[i, 0]]*len(peaks), color='r', s=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b48d2b8-62d5-4d7c-b1f2-0814daa16e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))\n",
    "ax1 = fig.add_subplot(111)\n",
    "# ax2 = fig.add_subplot(122)\n",
    "\n",
    "cp = ax1.contourf(frq[:,:], Ib[:,:], 10*np.log(mag[:,:]), vmin = -110)\n",
    "# cp2 = ax2.contourf(frq[:,:], Ib[:,:], phi[:,:])\n",
    "\n",
    "for i in range(mag.shape[0]):\n",
    "    peaks =  mag_peaks[i]\n",
    "    ax1.scatter(frq[i, peaks],[Ib[i, 0]]*len(peaks), color='r', s=1.5)\n",
    "    \n",
    "    # peaks =  phase_peaks[i]\n",
    "    # ax2.scatter(frq[i, peaks],[Ib[i, 0]]*len(peaks), color='r', s=1.2)\n",
    "\n",
    "plt.colorbar(cp, ax=ax1)\n",
    "# plt.colorbar(cp2, ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0945617a-4b13-4983-8fac-0ec6df8459db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Detect the shift of a given peak\n",
    "\n",
    "# Parameters to fiddle with\n",
    "max_distance = 2e7\n",
    "max_idx = 400\n",
    "#######\n",
    "starting_f = 4.674e9\n",
    "\n",
    "\n",
    "#######\n",
    "arr = np.abs( frq[0,mag_peaks[0]]- starting_f)\n",
    "idx = arr.argmin()\n",
    "\n",
    "fprevious = frq[0,mag_peaks[0]][idx]\n",
    "\n",
    "foundX = [fprevious]\n",
    "foundY = [Ib[0,0]]\n",
    "\n",
    "for i in range(max_idx):\n",
    "    peaks =  mag_peaks[i]\n",
    "    fs = frq[i, peaks]\n",
    "    \n",
    "    arr = np.abs(fs-fprevious)\n",
    "    distance = np.min(arr)\n",
    "    \n",
    "    if distance<max_distance:\n",
    "        idx = arr.argmin()\n",
    "        foundX.append(fs[idx])\n",
    "        foundY.append(Ib[i,0])\n",
    "        fprevious = fs[idx]\n",
    "\n",
    "foundX = np.array(foundX)\n",
    "foundY = np.array(foundY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19170fb9-79b3-4c29-8a8c-4a944b7905fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfit = np.polynomial.Polynomial.fit(foundY, foundX, deg=6,  domain=[Ib[0,0], Ib[-1,0]]) \n",
    "## Interpolation to measure in moving two tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988272de-7567-45d4-aac1-6f91303d15c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))\n",
    "ax1 = fig.add_subplot(111)\n",
    "# ax2 = fig.add_subplot(122)\n",
    "\n",
    "cp = ax1.contourf(frq[:,:], Ib[:,:], 10*np.log(mag[:,:]), vmin = -110)\n",
    "# cp2 = ax2.contourf(frq[:,:], Ib[:,:], phi[:,:])\n",
    "\n",
    "ax1.scatter(foundX, foundY, color='r', s=1.5)\n",
    "ax1.plot( pfit(Ib[:,0]), Ib[:,0], '--', c='darkorange')\n",
    "    # peaks =  phase_peaks[i]\n",
    "    # ax2.scatter(frq[i, peaks],[Ib[i, 0]]*len(peaks), color='r', s=1.2)\n",
    "\n",
    "plt.colorbar(cp, ax=ax1)\n",
    "# plt.colorbar(cp2, ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adf558e-a1cb-419b-a500-fa529bea1e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_current = np.linspace(0,10e-3, num=51)\n",
    "pfit(desired_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa29565-93ec-44a2-970f-0c1019b8b3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1a915e-7f3b-43c6-8263-95ca45c1ade5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<h2>Data analysis and plotting - Plasma (two tones) vs B field</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f41ec7-635b-4d9c-925b-9afae8a4bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = '20221118_sc-ncr_s21_meas.db'\n",
    "db_path  = os.path.join(r'D:\\QMET' + '\\\\' + sample_name + '\\\\', db_name)\n",
    "\n",
    "qc.initialise_or_create_database_at(db_path)\n",
    "\n",
    "RUN_ID = 62\n",
    "\n",
    "\n",
    "dataset = qc.load_by_run_spec(captured_run_id=RUN_ID)\n",
    "vnadc_vna_dict = dataset.to_pandas_dataframe_dict()\n",
    "#plt.plot(f, phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa00102-e63e-41d9-bd32-229f1004a850",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# VNA spectra\n",
    "vnadc_vna_0 = vnadc_vna_dict['ZNB20_S21_magnitude']\n",
    "vnadc_vna_1 = vnadc_vna_0.reset_index()\n",
    "\n",
    "frq = vnadc_vna_1['mw_source_rs_frequency'].to_numpy()\n",
    "mag = vnadc_vna_1['ZNB20_S21_magnitude'].to_numpy()\n",
    "Ib = vnadc_vna_1['current_source_current'].to_numpy()\n",
    "\n",
    "freq_size =  np.unique(frq).size\n",
    "current_size = np.unique(Ib).size\n",
    "\n",
    "\n",
    "m_size = (current_size, freq_size)\n",
    "frq = np.reshape(frq, m_size)\n",
    "mag = np.reshape(mag, m_size)\n",
    "Ib = np.reshape(Ib, m_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0541dbb9-e100-4352-9d29-ad0bfa4a4246",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p_current = np.array([0,1.63,3.07,4.54,5.89,7.52,8.65,9.74,5.53,2.84,7.06])*1e-3\n",
    "p_freq = np.array([9.82, 9.75,9.6,9.34,8.94,8.32,7.88,7.3,9.03,9.57,8.44])*1e9\n",
    "pfit = np.polynomial.Polynomial.fit(p_current, p_freq, deg=4,  domain=[Ib[0,0], Ib[-1,0]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b84c01-04ba-43d4-bdde-97f86a1923fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "plt.interactive(True)\n",
    "\n",
    "\n",
    "cp = ax1.contourf(frq[:,:], Ib[:,:], 10*np.log(mag[:,:]), vmin=-75, levels=110)\n",
    "\n",
    "\n",
    "ax1.scatter(p_freq, p_current, color='r', s=1.5)\n",
    "ax1.plot( pfit(Ib[:,0]), Ib[:,0], '--', c='darkorange')\n",
    "plt.colorbar(cp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952020cf-2ba7-4db4-8846-f4c206fbc549",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "from scipy.sparse import linalg as splin\n",
    "\n",
    "_has_matplotlib = True\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except ImportError:\n",
    "    _has_matplotlib = False\n",
    "    logging.warning(\"Matplotlib is not installed - plotting \"\n",
    "                    \"functionality disabled\")\n",
    "\n",
    "\n",
    "def log_iteration(ii, s0, u, g):\n",
    "    relative_change = np.linalg.norm(s0) / np.linalg.norm(u)\n",
    "    g_norm = np.linalg.norm(g)\n",
    "    logging.info('iteration {0:4d}: relative change = {1:.3e}, '\n",
    "                 'gradient norm = {2:.3e}\\n'.format(ii,\n",
    "                                                    relative_change,\n",
    "                                                    g_norm))\n",
    "\n",
    "\n",
    "def TVRegDiff(data, itern, alph, u0=None, scale='small', ep=1e-6, dx=None,\n",
    "              plotflag=_has_matplotlib, diagflag=True, precondflag=True,\n",
    "              diffkernel='abs', cgtol=1e-4, cgmaxit=100):\n",
    "    \"\"\"\n",
    "    Estimate derivatives from noisy data based using the Total \n",
    "    Variation Regularized Numerical Differentiation (TVDiff) \n",
    "    algorithm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : ndarray\n",
    "        One-dimensional array containing series data to be\n",
    "        differentiated.\n",
    "    itern : int\n",
    "        Number of iterations to run the main loop.  A stopping\n",
    "        condition based on the norm of the gradient vector g\n",
    "        below would be an easy modification.  No default value.\n",
    "    alph : float    \n",
    "        Regularization parameter.  This is the main parameter\n",
    "        to fiddle with.  Start by varying by orders of\n",
    "        magnitude until reasonable results are obtained.  A\n",
    "        value to the nearest power of 10 is usally adequate.\n",
    "        No default value.  Higher values increase\n",
    "        regularization strenght and improve conditioning.\n",
    "    u0 : ndarray, optional\n",
    "        Initialization of the iteration.  Default value is the\n",
    "        naive derivative (without scaling), of appropriate\n",
    "        length (this being different for the two methods).\n",
    "        Although the solution is theoretically independent of\n",
    "        the initialization, a poor choice can exacerbate\n",
    "        conditioning issues when the linear system is solved.\n",
    "    scale : {large' or 'small' (case insensitive)}, str, optional   \n",
    "        Default is 'small'.  'small' has somewhat better boundary\n",
    "        behavior, but becomes unwieldly for data larger than\n",
    "        1000 entries or so.  'large' has simpler numerics but\n",
    "        is more efficient for large-scale problems.  'large' is\n",
    "        more readily modified for higher-order derivatives,\n",
    "        since the implicit differentiation matrix is square.\n",
    "    ep : float, optional \n",
    "        Parameter for avoiding division by zero.  Default value\n",
    "        is 1e-6.  Results should not be very sensitive to the\n",
    "        value.  Larger values improve conditioning and\n",
    "        therefore speed, while smaller values give more\n",
    "        accurate results with sharper jumps.\n",
    "    dx : float, optional    \n",
    "        Grid spacing, used in the definition of the derivative\n",
    "        operators.  Default is the reciprocal of the data size.\n",
    "    plotflag : bool, optional\n",
    "        Flag whether to display plot at each iteration.\n",
    "        Default is True.  Useful, but adds significant\n",
    "        running time.\n",
    "    diagflag : bool, optional\n",
    "        Flag whether to display diagnostics at each\n",
    "        iteration.  Default is True.  Useful for diagnosing\n",
    "        preconditioning problems.  When tolerance is not met,\n",
    "        an early iterate being best is more worrying than a\n",
    "        large relative residual.\n",
    "    precondflag: bool, optional\n",
    "        Flag whether to use a preconditioner for conjugate gradient solution.\n",
    "        Default is True. While in principle it should speed things up, \n",
    "        sometimes the preconditioner can cause convergence problems instead,\n",
    "        and should be turned off. Note that this mostly makes sense for 'small'\n",
    "        scale problems; for 'large' ones, the improved preconditioner is one\n",
    "        of the main features of the algorithms and turning it off defeats the\n",
    "        point.\n",
    "    diffkernel: str, optional\n",
    "        Kernel to use in the integral to smooth the derivative. By default it's\n",
    "        the absolute value, |u'| (value: \"abs\"). However, it can be changed to\n",
    "        being the square, (u')^2 (value: \"sq\"). The latter produces smoother\n",
    "        derivatives, whereas the absolute values tends to make them more blocky.\n",
    "        Default is abs.\n",
    "    cgtol: float, optional\n",
    "        Tolerance to use in conjugate gradient optimisation. Default is 1e-4.\n",
    "    cgmaxit: int, optional\n",
    "        Maximum number of iterations to use in conjugate gradient optimisation. \n",
    "        Default is 100\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    u : ndarray\n",
    "        Estimate of the regularized derivative of data.  Due to\n",
    "        different grid assumptions, length(u) = length(data) + 1\n",
    "        if scale = 'small', otherwise length(u) = length(data).\n",
    "    \"\"\"\n",
    "\n",
    "    # Make sure we have a column vector\n",
    "    data = np.array(data)\n",
    "    assert len(data.shape) == 1, \"data is not one-dimensional\"\n",
    "    # Get the data size.\n",
    "    n = len(data)\n",
    "\n",
    "    # Default checking. (u0 is done separately within each method.)\n",
    "    if dx is None:\n",
    "        dx = 1.0 / n\n",
    "\n",
    "    # Different methods for small- and large-scale problems.\n",
    "    if (scale.lower() == 'small'):\n",
    "\n",
    "        # Differentiation operator\n",
    "        d0 = -np.ones(n)/dx\n",
    "        du = np.ones(n-1)/dx\n",
    "        dl = np.zeros(n-1)\n",
    "        dl[-1] = d0[-1]\n",
    "        d0[-1] *= -1\n",
    "\n",
    "        D = sparse.diags([dl, d0, du], [-1, 0, 1])\n",
    "        DT = D.transpose()\n",
    "\n",
    "        # Antidifferentiation and its adjoint\n",
    "        def A(x): return (np.cumsum(x) - 0.5 * (x + x[0])) * dx\n",
    "\n",
    "        def AT(x): return np.concatenate([[sum(x[1:])/2.0],\n",
    "                                          (sum(x)-np.cumsum(x)+0.5*x)[1:]])*dx\n",
    "\n",
    "        # Default initialization is naive derivative\n",
    "\n",
    "        if u0 is None:\n",
    "            u0 = D*data\n",
    "\n",
    "        u = u0.copy()\n",
    "        # Since Au( 0 ) = 0, we need to adjust.\n",
    "        ofst = data[0]\n",
    "        # Precompute.\n",
    "        ATb = AT(ofst - data)        # input: size n\n",
    "\n",
    "        # Main loop.\n",
    "        for ii in range(1, itern+1):\n",
    "            if diffkernel == 'abs':\n",
    "                # Diagonal matrix of weights, for linearizing E-L equation.\n",
    "                Q = sparse.spdiags(1. / (np.sqrt((D * u)**2 + ep)), 0, n, n)\n",
    "                # Linearized diffusion matrix, also approximation of Hessian.\n",
    "                L = dx * DT * Q * D\n",
    "            elif diffkernel == 'sq':\n",
    "                L = dx * DT * D\n",
    "            else:\n",
    "                raise ValueError('Invalid diffkernel value')\n",
    "\n",
    "            # Gradient of functional.\n",
    "            g = AT(A(u)) + ATb + alph * L * u\n",
    "\n",
    "            # Prepare to solve linear equation.\n",
    "            if precondflag:\n",
    "                # Simple preconditioner.\n",
    "                P = alph * sparse.spdiags(L.diagonal() + 1, 0, n, n)\n",
    "            else:\n",
    "                P = None\n",
    "\n",
    "            def linop(v): return (alph * L * v + AT(A(v)))\n",
    "            linop = splin.LinearOperator((n, n), linop)\n",
    "\n",
    "            s, info_i = sparse.linalg.cg(\n",
    "                linop, g, x0=None, tol=cgtol, maxiter=cgmaxit,\n",
    "                callback=None, M=P, atol='legacy')\n",
    "\n",
    "            if diagflag:\n",
    "                log_iteration(ii, s[0], u, g)\n",
    "                if (info_i > 0):\n",
    "                    logging.warning(\n",
    "                        \"WARNING - convergence to tolerance not achieved!\")\n",
    "                elif (info_i < 0):\n",
    "                    logging.warning(\"WARNING - illegal input or breakdown\")\n",
    "\n",
    "            # Update solution.\n",
    "            u = u - s\n",
    "            # Display plot.\n",
    "            if plotflag:\n",
    "                plt.plot(u)\n",
    "                plt.show()\n",
    "\n",
    "    elif (scale.lower() == 'large'):\n",
    "\n",
    "        # Construct anti-differentiation operator and its adjoint.\n",
    "        def A(v): return np.cumsum(v)\n",
    "\n",
    "        def AT(w): return (sum(w) * np.ones(len(w)) -\n",
    "                           np.transpose(np.concatenate(([0.0],\n",
    "                                                        np.cumsum(w[:-1])))))\n",
    "        # Construct differentiation matrix.\n",
    "        c = np.ones(n)\n",
    "        D = sparse.spdiags([-c, c], [0, 1], n, n) / dx\n",
    "        mask = np.ones((n, n))\n",
    "        mask[-1, -1] = 0.0\n",
    "        D = sparse.dia_matrix(D.multiply(mask))\n",
    "        DT = D.transpose()\n",
    "        # Since Au( 0 ) = 0, we need to adjust.\n",
    "        data = data - data[0]\n",
    "        # Default initialization is naive derivative.\n",
    "        if u0 is None:\n",
    "            u0 = np.concatenate(([0], np.diff(data)))\n",
    "        u = u0\n",
    "        # Precompute.\n",
    "        ATd = AT(data)\n",
    "\n",
    "        # Main loop.\n",
    "        for ii in range(1, itern + 1):\n",
    "\n",
    "            if diffkernel == 'abs':\n",
    "                # Diagonal matrix of weights, for linearizing E-L equation.\n",
    "                Q = sparse.spdiags(1. / (np.sqrt((D * u)**2 + ep)), 0, n, n)\n",
    "                # Linearized diffusion matrix, also approximation of Hessian.\n",
    "                L = DT * Q * D\n",
    "            elif diffkernel == 'sq':\n",
    "                L = DT * D\n",
    "            else:\n",
    "                raise ValueError('Invalid diffkernel value')\n",
    "\n",
    "            # Gradient of functional.\n",
    "            g = AT(A(u)) - ATd\n",
    "            g = g + alph * L * u\n",
    "            # Build preconditioner.\n",
    "            if precondflag:\n",
    "                c = np.cumsum(range(n, 0, -1))\n",
    "                B = alph * L + sparse.spdiags(c[::-1], 0, n, n)\n",
    "                # droptol = 1.0e-2\n",
    "                R = sparse.dia_matrix(np.linalg.cholesky(B.todense()))\n",
    "                P = np.dot(R.transpose(), R)\n",
    "            else:\n",
    "                P = None\n",
    "            # Prepare to solve linear equation.\n",
    "\n",
    "            def linop(v): return (alph * L * v + AT(A(v)))\n",
    "            linop = splin.LinearOperator((n, n), linop)\n",
    "\n",
    "            s, info_i = sparse.linalg.cg(\n",
    "                linop, -g, x0=None, tol=cgtol, maxiter=cgmaxit, callback=None,\n",
    "                M=P, atol='legacy')\n",
    "            if diagflag:\n",
    "                log_iteration(ii, s[0], u, g)\n",
    "                if (info_i > 0):\n",
    "                    logging.warning(\n",
    "                        \"WARNING - convergence to tolerance not achieved!\")\n",
    "                elif (info_i < 0):\n",
    "                    logging.warning(\"WARNING - illegal input or breakdown\")\n",
    "\n",
    "            # Update current solution\n",
    "            u = u + s\n",
    "            # Display plot\n",
    "            if plotflag:\n",
    "                plt.plot(u / dx)\n",
    "                plt.show()\n",
    "\n",
    "        u = u / dx\n",
    "\n",
    "    return u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6ec357-dea1-4caa-b1c0-b22d70c88878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454eedcb-f5cf-473f-8a10-af187ffb71e6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def moving_average(a, n=3) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "\n",
    "mag_peaks_in_freqs = []\n",
    "\n",
    "for k in tqdm.tqdm(range(Ib.shape[0])):\n",
    "    # data = i_up[k, :] - i_up[k, 0]\n",
    "    data = mag[k, :]\n",
    "    s_data = moving_average(data, n=50)\n",
    "    s_frq= moving_average(frq[0,:], n=50)\n",
    "    \n",
    "    thrs = np.max(s_data)-2e-3\n",
    "    \n",
    "    m_peaks = check_for_peaks(np.log(s_data), threshold=-70)\n",
    "    # m_peaks = remove_overdetection_peaks(s_data, s_frq, m_peaks, minimum_freq_spacing=0.1e9)\n",
    "    \n",
    "    mag_peaks_in_freqs.append(s_frq[m_peaks])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fb7fc0-964d-43cd-ac22-bdeb75c7eec2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))\n",
    "ax1 = fig.add_subplot(111)\n",
    "# ax2 = fig.add_subplot(122)\n",
    "\n",
    "\n",
    "for i in range(mag.shape[0]):\n",
    "    peaks =  mag_peaks_in_freqs[i]\n",
    "    ax1.scatter(peaks,[Ib[i, 0]]*len(peaks), color='r', s=0.5)\n",
    "    \n",
    "    # peaks =  phase_peaks[i]\n",
    "    # ax2.scatter(frq[i, peaks, 0],[Ib[i, 0]]*len(peaks), color='r', s=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb4dcfd-2ac3-47fa-93bc-9da36f44412b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "data = mag[k, :]\n",
    "s_data = moving_average(data, n=50)\n",
    "s_frq= moving_average(frq[0,:], n=50)\n",
    "gs_data = np.gradient(s_data)\n",
    "plt.plot(frq[0,:],data)\n",
    "plt.plot(s_frq,s_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e871c9c1-3283-4398-83dd-2f5510f63b35",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "g_peaks = check_for_peaks(gs_data, threshold=2e-5)\n",
    "g_peaks = remove_overdetection_peaks(gs_data, s_frq, g_peaks, minimum_freq_spacing=0.1e9)\n",
    "plt.plot(gs_data)\n",
    "\n",
    "# plt.vlines(g_peaks, np.min(gs_data), np.max(gs_data),color='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bcac05-4b5c-4866-b880-3f52d606b182",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "m_peaks = check_for_peaks(s_data, threshold=4e-3)\n",
    "m_peaks = remove_overdetection_peaks(s_data, s_frq, m_peaks, minimum_freq_spacing=0.1e9)\n",
    "plt.plot(s_data)\n",
    "\n",
    "plt.vlines(m_peaks, np.min(s_data), np.max(s_data),color='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c46c3b0-dd72-4b5f-9ca2-8579c0b3799a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cabdd5-02f1-4069-aa49-2ff75e770dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db_name = '20221118_sc-ncr_iv_curves.db'\n",
    "db_path  = os.path.join(r'D:\\QMET' + '\\\\' + sample_name + '\\\\', db_name)\n",
    "\n",
    "qc.initialise_or_create_database_at(db_path)\n",
    "\n",
    "\n",
    "# loading\n",
    "RUN_ID = 3\n",
    "dataset = qc.load_by_run_spec(captured_run_id=RUN_ID)\n",
    "ivf_dict = dataset.to_pandas_dataframe_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa59773-d91f-4356-8785-7f0ee0bbbcc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h5>Data shaping</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294f9447-6bf9-43d0-968f-dc288ec3e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# up ramp\n",
    "ivf_up_0 = ivf_dict['adwin_up_ramp']\n",
    "ivf_up_1 = ivf_up_0.reset_index()\n",
    "\n",
    "Ib_up = ivf_up_1['current_source_current'].to_numpy()\n",
    "v_up = ivf_up_1['adwin_input_2_voltage_up'].to_numpy()\n",
    "i_up = ivf_up_1['adwin_up_ramp'].to_numpy()\n",
    "\n",
    "# down ramp\n",
    "ivf_down_0 = ivf_dict['adwin_down_ramp']\n",
    "ivf_down_1 = ivf_down_0.reset_index()\n",
    "\n",
    "Ib_down = ivf_down_1['current_source_current'].to_numpy()\n",
    "v_down = ivf_down_1['adwin_input_2_voltage_down'].to_numpy()\n",
    "i_down = ivf_down_1['adwin_down_ramp'].to_numpy()\n",
    "\n",
    "# reshape to form a 2D array\n",
    "# if RUN_ID == 4:\n",
    "#     N = 20000\n",
    "# if RUN_ID == 38:\n",
    "#     N = 25234\n",
    "# if RUN_ID == 45:\n",
    "#     N = 11998    \n",
    "N = np.unique(Ib_up).shape[0]\n",
    "\n",
    "size = (N, -1)\n",
    "\n",
    "Ib_up = np.reshape(Ib_up, size)\n",
    "v_up = np.reshape(v_up, size)\n",
    "i_up = np.reshape(i_up, size)\n",
    "Ib_down = np.reshape(Ib_down, size)\n",
    "v_down = np.reshape(v_down, size)\n",
    "i_down = np.reshape(i_down, size)\n",
    "\n",
    "# # divide into low-to-high and high-to-low\n",
    "# M = len(i_up)\n",
    "# zero_index_up = np.argmin(np.abs(i_up[51]))\n",
    "# zero_index_down = np.argmin(np.abs(i_down[51]))\n",
    "\n",
    "# v_lh = np.zeros((M, 2*N - zero_index_down - zero_index_up))\n",
    "# v_hl = np.zeros((M, zero_index_down + zero_index_up))\n",
    "# i_lh = np.zeros((M, 2*N - zero_index_down - zero_index_up))\n",
    "# i_hl = np.zeros((M, zero_index_down + zero_index_up))\n",
    "\n",
    "# for i in range(M):\n",
    "#     v_lh[i] = np.concatenate(( np.flip(v_down[i][zero_index_down:]), v_up[i][zero_index_up:] ))\n",
    "#     v_hl[i] = np.concatenate(( v_up[i][:zero_index_up], np.flip(v_down[i][:zero_index_down]) ))\n",
    "#     i_lh[i] = np.concatenate(( np.flip(i_down[i][zero_index_down:]), i_up[i][zero_index_up:] ))\n",
    "#     i_hl[i] = np.concatenate(( i_up[i][:zero_index_up], np.flip(i_down[i][:zero_index_down]) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad73db4-89f1-4ba2-8624-9511a275c092",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h5>Plotting</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af71c096-83a4-4c6f-bbf0-b47081270992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plotting\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "voltage_scaling = 1e3\n",
    "voltage_offset = 0.085\n",
    "current_scaling = 1e9\n",
    "\n",
    "h = 6.626e-34\n",
    "e = 1.6e-19\n",
    "\n",
    "for order in [1,3,9]:\n",
    "    plt.plot( pfit(Ib_up[:,0])*h/2/e*voltage_scaling*order, Ib_up[:,0], '--', c='darkorange')\n",
    "    boxIb = 0.0e-3+order*5e-4\n",
    "    \n",
    "    plt.text( pfit(boxIb)*h/2/e*voltage_scaling*order+0.008, boxIb, \"n=%i\" % order, size=12, bbox=dict(boxstyle=\"round\",\n",
    "                   ec=(1., 0.5, 0.5),\n",
    "                   fc=(1., 0.8, 0.8),\n",
    "                   alpha=0.75))\n",
    "\n",
    "plt.imshow(current_scaling*i_up, aspect='auto', \n",
    "           extent=[ voltage_scaling*(np.min(v_up[0, :])) + voltage_offset, voltage_scaling*(np.max(v_up[0, :])) + voltage_offset, np.min(Ib_up[:, 0]), np.max(Ib_up[:,0]) ], \n",
    "           cmap='RdBu', origin='lower')\n",
    "plt.xlabel('Voltage (mV)')\n",
    "plt.ylabel('Coil current ($A$)')\n",
    "plt.colorbar(label='DC current (nA)')\n",
    "plt.savefig(\"plasma_scaling_vs_ivflux.png\")\n",
    "# plt.hlines(-1, -5, 5, linestyles='dashed', colors='black', alpha=0.5)\n",
    "# plt.hlines(0, -5, 5, linestyles='dashed', colors='black', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4b837c-3bcc-4992-9c11-117707df2449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc6c4fa-8a57-46a7-ae85-d54417bae0f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
